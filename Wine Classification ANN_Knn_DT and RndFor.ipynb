{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Wine Classification Using KNN, ANN, DTree and Random Forest\n",
    "    Author: Adeyemi Adedoyin Simeon\n",
    "    Date: June 12, 2019\n",
    "    Venue: @ Offa (Home)\n",
    "    Version: 1.0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = load_wine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(wine.data,columns=wine.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['wine_class'] = wine.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['class_0' 'class_1' 'class_2']\n"
     ]
    }
   ],
   "source": [
    "print(wine.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wine Data Database\n",
      "====================\n",
      "\n",
      "Notes\n",
      "-----\n",
      "Data Set Characteristics:\n",
      "    :Number of Instances: 178 (50 in each of three classes)\n",
      "    :Number of Attributes: 13 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      " \t\t- 1) Alcohol\n",
      " \t\t- 2) Malic acid\n",
      " \t\t- 3) Ash\n",
      "\t\t- 4) Alcalinity of ash  \n",
      " \t\t- 5) Magnesium\n",
      "\t\t- 6) Total phenols\n",
      " \t\t- 7) Flavanoids\n",
      " \t\t- 8) Nonflavanoid phenols\n",
      " \t\t- 9) Proanthocyanins\n",
      "\t\t- 10)Color intensity\n",
      " \t\t- 11)Hue\n",
      " \t\t- 12)OD280/OD315 of diluted wines\n",
      " \t\t- 13)Proline\n",
      "        \t- class:\n",
      "                - class_0\n",
      "                - class_1\n",
      "                - class_2\n",
      "\t\t\n",
      "    :Summary Statistics:\n",
      "    \n",
      "    ============================= ==== ===== ======= =====\n",
      "                                   Min   Max   Mean     SD\n",
      "    ============================= ==== ===== ======= =====\n",
      "    Alcohol:                      11.0  14.8    13.0   0.8\n",
      "    Malic Acid:                   0.74  5.80    2.34  1.12\n",
      "    Ash:                          1.36  3.23    2.36  0.27\n",
      "    Alcalinity of Ash:            10.6  30.0    19.5   3.3\n",
      "    Magnesium:                    70.0 162.0    99.7  14.3\n",
      "    Total Phenols:                0.98  3.88    2.29  0.63\n",
      "    Flavanoids:                   0.34  5.08    2.03  1.00\n",
      "    Nonflavanoid Phenols:         0.13  0.66    0.36  0.12\n",
      "    Proanthocyanins:              0.41  3.58    1.59  0.57\n",
      "    Colour Intensity:              1.3  13.0     5.1   2.3\n",
      "    Hue:                          0.48  1.71    0.96  0.23\n",
      "    OD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\n",
      "    Proline:                       278  1680     746   315\n",
      "    ============================= ==== ===== ======= =====\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: class_0 (59), class_1 (71), class_2 (48)\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "This is a copy of UCI ML Wine recognition datasets.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\n",
      "\n",
      "The data is the results of a chemical analysis of wines grown in the same\n",
      "region in Italy by three different cultivators. There are thirteen different\n",
      "measurements taken for different constituents found in the three types of\n",
      "wine.\n",
      "\n",
      "Original Owners: \n",
      "\n",
      "Forina, M. et al, PARVUS - \n",
      "An Extendible Package for Data Exploration, Classification and Correlation. \n",
      "Institute of Pharmaceutical and Food Analysis and Technologies,\n",
      "Via Brigata Salerno, 16147 Genoa, Italy.\n",
      "\n",
      "Citation:\n",
      "\n",
      "Lichman, M. (2013). UCI Machine Learning Repository\n",
      "[http://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\n",
      "School of Information and Computer Science. \n",
      "\n",
      "References\n",
      "----------\n",
      "(1) \n",
      "S. Aeberhard, D. Coomans and O. de Vel, \n",
      "Comparison of Classifiers in High Dimensional Settings, \n",
      "Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of \n",
      "Mathematics and Statistics, James Cook University of North Queensland. \n",
      "(Also submitted to Technometrics). \n",
      "\n",
      "The data was used with many others for comparing various \n",
      "classifiers. The classes are separable, though only RDA \n",
      "has achieved 100% correct classification. \n",
      "(RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data)) \n",
      "(All results using the leave-one-out technique) \n",
      "\n",
      "(2) \n",
      "S. Aeberhard, D. Coomans and O. de Vel, \n",
      "\"THE CLASSIFICATION PERFORMANCE OF RDA\" \n",
      "Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of \n",
      "Mathematics and Statistics, James Cook University of North Queensland. \n",
      "(Also submitted to Journal of Chemometrics). \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(wine.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "      <th>wine_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.640000</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.380000</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.680000</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.800000</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.320000</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14.20</td>\n",
       "      <td>1.76</td>\n",
       "      <td>2.45</td>\n",
       "      <td>15.2</td>\n",
       "      <td>112.0</td>\n",
       "      <td>3.27</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.97</td>\n",
       "      <td>6.750000</td>\n",
       "      <td>1.05</td>\n",
       "      <td>2.85</td>\n",
       "      <td>1450.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14.39</td>\n",
       "      <td>1.87</td>\n",
       "      <td>2.45</td>\n",
       "      <td>14.6</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.52</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.98</td>\n",
       "      <td>5.250000</td>\n",
       "      <td>1.02</td>\n",
       "      <td>3.58</td>\n",
       "      <td>1290.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14.06</td>\n",
       "      <td>2.15</td>\n",
       "      <td>2.61</td>\n",
       "      <td>17.6</td>\n",
       "      <td>121.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>2.51</td>\n",
       "      <td>0.31</td>\n",
       "      <td>1.25</td>\n",
       "      <td>5.050000</td>\n",
       "      <td>1.06</td>\n",
       "      <td>3.58</td>\n",
       "      <td>1295.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14.83</td>\n",
       "      <td>1.64</td>\n",
       "      <td>2.17</td>\n",
       "      <td>14.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.98</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.98</td>\n",
       "      <td>5.200000</td>\n",
       "      <td>1.08</td>\n",
       "      <td>2.85</td>\n",
       "      <td>1045.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>13.86</td>\n",
       "      <td>1.35</td>\n",
       "      <td>2.27</td>\n",
       "      <td>16.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>2.98</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.22</td>\n",
       "      <td>1.85</td>\n",
       "      <td>7.220000</td>\n",
       "      <td>1.01</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1045.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>14.10</td>\n",
       "      <td>2.16</td>\n",
       "      <td>2.30</td>\n",
       "      <td>18.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>2.95</td>\n",
       "      <td>3.32</td>\n",
       "      <td>0.22</td>\n",
       "      <td>2.38</td>\n",
       "      <td>5.750000</td>\n",
       "      <td>1.25</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1510.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>14.12</td>\n",
       "      <td>1.48</td>\n",
       "      <td>2.32</td>\n",
       "      <td>16.8</td>\n",
       "      <td>95.0</td>\n",
       "      <td>2.20</td>\n",
       "      <td>2.43</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.57</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.17</td>\n",
       "      <td>2.82</td>\n",
       "      <td>1280.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.75</td>\n",
       "      <td>1.73</td>\n",
       "      <td>2.41</td>\n",
       "      <td>16.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.81</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>1.15</td>\n",
       "      <td>2.90</td>\n",
       "      <td>1320.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.75</td>\n",
       "      <td>1.73</td>\n",
       "      <td>2.39</td>\n",
       "      <td>11.4</td>\n",
       "      <td>91.0</td>\n",
       "      <td>3.10</td>\n",
       "      <td>3.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>1.25</td>\n",
       "      <td>2.73</td>\n",
       "      <td>1150.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14.38</td>\n",
       "      <td>1.87</td>\n",
       "      <td>2.38</td>\n",
       "      <td>12.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>3.30</td>\n",
       "      <td>3.64</td>\n",
       "      <td>0.29</td>\n",
       "      <td>2.96</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>1.20</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1547.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>13.63</td>\n",
       "      <td>1.81</td>\n",
       "      <td>2.70</td>\n",
       "      <td>17.2</td>\n",
       "      <td>112.0</td>\n",
       "      <td>2.85</td>\n",
       "      <td>2.91</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.46</td>\n",
       "      <td>7.300000</td>\n",
       "      <td>1.28</td>\n",
       "      <td>2.88</td>\n",
       "      <td>1310.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>14.30</td>\n",
       "      <td>1.92</td>\n",
       "      <td>2.72</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.14</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.97</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>1.07</td>\n",
       "      <td>2.65</td>\n",
       "      <td>1280.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>13.83</td>\n",
       "      <td>1.57</td>\n",
       "      <td>2.62</td>\n",
       "      <td>20.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>2.95</td>\n",
       "      <td>3.40</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.72</td>\n",
       "      <td>6.600000</td>\n",
       "      <td>1.13</td>\n",
       "      <td>2.57</td>\n",
       "      <td>1130.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>14.19</td>\n",
       "      <td>1.59</td>\n",
       "      <td>2.48</td>\n",
       "      <td>16.5</td>\n",
       "      <td>108.0</td>\n",
       "      <td>3.30</td>\n",
       "      <td>3.93</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1.86</td>\n",
       "      <td>8.700000</td>\n",
       "      <td>1.23</td>\n",
       "      <td>2.82</td>\n",
       "      <td>1680.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>13.64</td>\n",
       "      <td>3.10</td>\n",
       "      <td>2.56</td>\n",
       "      <td>15.2</td>\n",
       "      <td>116.0</td>\n",
       "      <td>2.70</td>\n",
       "      <td>3.03</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.66</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>0.96</td>\n",
       "      <td>3.36</td>\n",
       "      <td>845.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>14.06</td>\n",
       "      <td>1.63</td>\n",
       "      <td>2.28</td>\n",
       "      <td>16.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.10</td>\n",
       "      <td>5.650000</td>\n",
       "      <td>1.09</td>\n",
       "      <td>3.71</td>\n",
       "      <td>780.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>12.93</td>\n",
       "      <td>3.80</td>\n",
       "      <td>2.65</td>\n",
       "      <td>18.6</td>\n",
       "      <td>102.0</td>\n",
       "      <td>2.41</td>\n",
       "      <td>2.41</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.98</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.52</td>\n",
       "      <td>770.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>13.71</td>\n",
       "      <td>1.86</td>\n",
       "      <td>2.36</td>\n",
       "      <td>16.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.61</td>\n",
       "      <td>2.88</td>\n",
       "      <td>0.27</td>\n",
       "      <td>1.69</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>1.11</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1035.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>12.85</td>\n",
       "      <td>1.60</td>\n",
       "      <td>2.52</td>\n",
       "      <td>17.8</td>\n",
       "      <td>95.0</td>\n",
       "      <td>2.48</td>\n",
       "      <td>2.37</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.46</td>\n",
       "      <td>3.930000</td>\n",
       "      <td>1.09</td>\n",
       "      <td>3.63</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>13.50</td>\n",
       "      <td>1.81</td>\n",
       "      <td>2.61</td>\n",
       "      <td>20.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2.53</td>\n",
       "      <td>2.61</td>\n",
       "      <td>0.28</td>\n",
       "      <td>1.66</td>\n",
       "      <td>3.520000</td>\n",
       "      <td>1.12</td>\n",
       "      <td>3.82</td>\n",
       "      <td>845.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>13.05</td>\n",
       "      <td>2.05</td>\n",
       "      <td>3.22</td>\n",
       "      <td>25.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>2.63</td>\n",
       "      <td>2.68</td>\n",
       "      <td>0.47</td>\n",
       "      <td>1.92</td>\n",
       "      <td>3.580000</td>\n",
       "      <td>1.13</td>\n",
       "      <td>3.20</td>\n",
       "      <td>830.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>13.39</td>\n",
       "      <td>1.77</td>\n",
       "      <td>2.62</td>\n",
       "      <td>16.1</td>\n",
       "      <td>93.0</td>\n",
       "      <td>2.85</td>\n",
       "      <td>2.94</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.45</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>0.92</td>\n",
       "      <td>3.22</td>\n",
       "      <td>1195.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>13.30</td>\n",
       "      <td>1.72</td>\n",
       "      <td>2.14</td>\n",
       "      <td>17.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>2.40</td>\n",
       "      <td>2.19</td>\n",
       "      <td>0.27</td>\n",
       "      <td>1.35</td>\n",
       "      <td>3.950000</td>\n",
       "      <td>1.02</td>\n",
       "      <td>2.77</td>\n",
       "      <td>1285.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>13.87</td>\n",
       "      <td>1.90</td>\n",
       "      <td>2.80</td>\n",
       "      <td>19.4</td>\n",
       "      <td>107.0</td>\n",
       "      <td>2.95</td>\n",
       "      <td>2.97</td>\n",
       "      <td>0.37</td>\n",
       "      <td>1.76</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>1.25</td>\n",
       "      <td>3.40</td>\n",
       "      <td>915.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>14.02</td>\n",
       "      <td>1.68</td>\n",
       "      <td>2.21</td>\n",
       "      <td>16.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.33</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.98</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.59</td>\n",
       "      <td>1035.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>13.32</td>\n",
       "      <td>3.24</td>\n",
       "      <td>2.38</td>\n",
       "      <td>21.5</td>\n",
       "      <td>92.0</td>\n",
       "      <td>1.93</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.45</td>\n",
       "      <td>1.25</td>\n",
       "      <td>8.420000</td>\n",
       "      <td>0.55</td>\n",
       "      <td>1.62</td>\n",
       "      <td>650.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>13.08</td>\n",
       "      <td>3.90</td>\n",
       "      <td>2.36</td>\n",
       "      <td>21.5</td>\n",
       "      <td>113.0</td>\n",
       "      <td>1.41</td>\n",
       "      <td>1.39</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.14</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1.33</td>\n",
       "      <td>550.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>13.50</td>\n",
       "      <td>3.12</td>\n",
       "      <td>2.62</td>\n",
       "      <td>24.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>1.40</td>\n",
       "      <td>1.57</td>\n",
       "      <td>0.22</td>\n",
       "      <td>1.25</td>\n",
       "      <td>8.600000</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.30</td>\n",
       "      <td>500.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>12.79</td>\n",
       "      <td>2.67</td>\n",
       "      <td>2.48</td>\n",
       "      <td>22.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>1.48</td>\n",
       "      <td>1.36</td>\n",
       "      <td>0.24</td>\n",
       "      <td>1.26</td>\n",
       "      <td>10.800000</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1.47</td>\n",
       "      <td>480.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>13.11</td>\n",
       "      <td>1.90</td>\n",
       "      <td>2.75</td>\n",
       "      <td>25.5</td>\n",
       "      <td>116.0</td>\n",
       "      <td>2.20</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.56</td>\n",
       "      <td>7.100000</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.33</td>\n",
       "      <td>425.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>13.23</td>\n",
       "      <td>3.30</td>\n",
       "      <td>2.28</td>\n",
       "      <td>18.5</td>\n",
       "      <td>98.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.87</td>\n",
       "      <td>10.520000</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.51</td>\n",
       "      <td>675.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>12.58</td>\n",
       "      <td>1.29</td>\n",
       "      <td>2.10</td>\n",
       "      <td>20.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1.48</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.40</td>\n",
       "      <td>7.600000</td>\n",
       "      <td>0.58</td>\n",
       "      <td>1.55</td>\n",
       "      <td>640.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>13.17</td>\n",
       "      <td>5.19</td>\n",
       "      <td>2.32</td>\n",
       "      <td>22.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>1.74</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.55</td>\n",
       "      <td>7.900000</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.48</td>\n",
       "      <td>725.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>13.84</td>\n",
       "      <td>4.12</td>\n",
       "      <td>2.38</td>\n",
       "      <td>19.5</td>\n",
       "      <td>89.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1.56</td>\n",
       "      <td>9.010000</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1.64</td>\n",
       "      <td>480.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>12.45</td>\n",
       "      <td>3.03</td>\n",
       "      <td>2.64</td>\n",
       "      <td>27.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1.90</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.63</td>\n",
       "      <td>1.14</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.73</td>\n",
       "      <td>880.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>14.34</td>\n",
       "      <td>1.68</td>\n",
       "      <td>2.70</td>\n",
       "      <td>25.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>1.31</td>\n",
       "      <td>0.53</td>\n",
       "      <td>2.70</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1.96</td>\n",
       "      <td>660.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>13.48</td>\n",
       "      <td>1.67</td>\n",
       "      <td>2.64</td>\n",
       "      <td>22.5</td>\n",
       "      <td>89.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.52</td>\n",
       "      <td>2.29</td>\n",
       "      <td>11.750000</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1.78</td>\n",
       "      <td>620.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>12.36</td>\n",
       "      <td>3.83</td>\n",
       "      <td>2.38</td>\n",
       "      <td>21.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.04</td>\n",
       "      <td>7.650000</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.58</td>\n",
       "      <td>520.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>13.69</td>\n",
       "      <td>3.26</td>\n",
       "      <td>2.54</td>\n",
       "      <td>20.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>1.83</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.80</td>\n",
       "      <td>5.880000</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.82</td>\n",
       "      <td>680.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>12.85</td>\n",
       "      <td>3.27</td>\n",
       "      <td>2.58</td>\n",
       "      <td>22.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.96</td>\n",
       "      <td>5.580000</td>\n",
       "      <td>0.87</td>\n",
       "      <td>2.11</td>\n",
       "      <td>570.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>12.96</td>\n",
       "      <td>3.45</td>\n",
       "      <td>2.35</td>\n",
       "      <td>18.5</td>\n",
       "      <td>106.0</td>\n",
       "      <td>1.39</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.94</td>\n",
       "      <td>5.280000</td>\n",
       "      <td>0.68</td>\n",
       "      <td>1.75</td>\n",
       "      <td>675.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>13.78</td>\n",
       "      <td>2.76</td>\n",
       "      <td>2.30</td>\n",
       "      <td>22.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.35</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.41</td>\n",
       "      <td>1.03</td>\n",
       "      <td>9.580000</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.68</td>\n",
       "      <td>615.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>13.73</td>\n",
       "      <td>4.36</td>\n",
       "      <td>2.26</td>\n",
       "      <td>22.5</td>\n",
       "      <td>88.0</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.15</td>\n",
       "      <td>6.620000</td>\n",
       "      <td>0.78</td>\n",
       "      <td>1.75</td>\n",
       "      <td>520.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>13.45</td>\n",
       "      <td>3.70</td>\n",
       "      <td>2.60</td>\n",
       "      <td>23.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.46</td>\n",
       "      <td>10.680000</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1.56</td>\n",
       "      <td>695.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>12.82</td>\n",
       "      <td>3.37</td>\n",
       "      <td>2.30</td>\n",
       "      <td>19.5</td>\n",
       "      <td>88.0</td>\n",
       "      <td>1.48</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.97</td>\n",
       "      <td>10.260000</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1.75</td>\n",
       "      <td>685.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>13.58</td>\n",
       "      <td>2.58</td>\n",
       "      <td>2.69</td>\n",
       "      <td>24.5</td>\n",
       "      <td>105.0</td>\n",
       "      <td>1.55</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.54</td>\n",
       "      <td>8.660000</td>\n",
       "      <td>0.74</td>\n",
       "      <td>1.80</td>\n",
       "      <td>750.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>13.40</td>\n",
       "      <td>4.60</td>\n",
       "      <td>2.86</td>\n",
       "      <td>25.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>1.98</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.27</td>\n",
       "      <td>1.11</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.92</td>\n",
       "      <td>630.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>12.20</td>\n",
       "      <td>3.03</td>\n",
       "      <td>2.32</td>\n",
       "      <td>19.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.73</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>0.66</td>\n",
       "      <td>1.83</td>\n",
       "      <td>510.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>12.77</td>\n",
       "      <td>2.39</td>\n",
       "      <td>2.28</td>\n",
       "      <td>19.5</td>\n",
       "      <td>86.0</td>\n",
       "      <td>1.39</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.64</td>\n",
       "      <td>9.899999</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1.63</td>\n",
       "      <td>470.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>14.16</td>\n",
       "      <td>2.51</td>\n",
       "      <td>2.48</td>\n",
       "      <td>20.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.44</td>\n",
       "      <td>1.24</td>\n",
       "      <td>9.700000</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1.71</td>\n",
       "      <td>660.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.700000</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.74</td>\n",
       "      <td>740.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.300000</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>750.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>13.27</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.56</td>\n",
       "      <td>835.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.300000</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "      <td>840.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>14.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.74</td>\n",
       "      <td>24.5</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.200000</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>560.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0      14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1      13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2      13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3      14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4      13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "5      14.20        1.76  2.45               15.2      112.0           3.27   \n",
       "6      14.39        1.87  2.45               14.6       96.0           2.50   \n",
       "7      14.06        2.15  2.61               17.6      121.0           2.60   \n",
       "8      14.83        1.64  2.17               14.0       97.0           2.80   \n",
       "9      13.86        1.35  2.27               16.0       98.0           2.98   \n",
       "10     14.10        2.16  2.30               18.0      105.0           2.95   \n",
       "11     14.12        1.48  2.32               16.8       95.0           2.20   \n",
       "12     13.75        1.73  2.41               16.0       89.0           2.60   \n",
       "13     14.75        1.73  2.39               11.4       91.0           3.10   \n",
       "14     14.38        1.87  2.38               12.0      102.0           3.30   \n",
       "15     13.63        1.81  2.70               17.2      112.0           2.85   \n",
       "16     14.30        1.92  2.72               20.0      120.0           2.80   \n",
       "17     13.83        1.57  2.62               20.0      115.0           2.95   \n",
       "18     14.19        1.59  2.48               16.5      108.0           3.30   \n",
       "19     13.64        3.10  2.56               15.2      116.0           2.70   \n",
       "20     14.06        1.63  2.28               16.0      126.0           3.00   \n",
       "21     12.93        3.80  2.65               18.6      102.0           2.41   \n",
       "22     13.71        1.86  2.36               16.6      101.0           2.61   \n",
       "23     12.85        1.60  2.52               17.8       95.0           2.48   \n",
       "24     13.50        1.81  2.61               20.0       96.0           2.53   \n",
       "25     13.05        2.05  3.22               25.0      124.0           2.63   \n",
       "26     13.39        1.77  2.62               16.1       93.0           2.85   \n",
       "27     13.30        1.72  2.14               17.0       94.0           2.40   \n",
       "28     13.87        1.90  2.80               19.4      107.0           2.95   \n",
       "29     14.02        1.68  2.21               16.0       96.0           2.65   \n",
       "..       ...         ...   ...                ...        ...            ...   \n",
       "148    13.32        3.24  2.38               21.5       92.0           1.93   \n",
       "149    13.08        3.90  2.36               21.5      113.0           1.41   \n",
       "150    13.50        3.12  2.62               24.0      123.0           1.40   \n",
       "151    12.79        2.67  2.48               22.0      112.0           1.48   \n",
       "152    13.11        1.90  2.75               25.5      116.0           2.20   \n",
       "153    13.23        3.30  2.28               18.5       98.0           1.80   \n",
       "154    12.58        1.29  2.10               20.0      103.0           1.48   \n",
       "155    13.17        5.19  2.32               22.0       93.0           1.74   \n",
       "156    13.84        4.12  2.38               19.5       89.0           1.80   \n",
       "157    12.45        3.03  2.64               27.0       97.0           1.90   \n",
       "158    14.34        1.68  2.70               25.0       98.0           2.80   \n",
       "159    13.48        1.67  2.64               22.5       89.0           2.60   \n",
       "160    12.36        3.83  2.38               21.0       88.0           2.30   \n",
       "161    13.69        3.26  2.54               20.0      107.0           1.83   \n",
       "162    12.85        3.27  2.58               22.0      106.0           1.65   \n",
       "163    12.96        3.45  2.35               18.5      106.0           1.39   \n",
       "164    13.78        2.76  2.30               22.0       90.0           1.35   \n",
       "165    13.73        4.36  2.26               22.5       88.0           1.28   \n",
       "166    13.45        3.70  2.60               23.0      111.0           1.70   \n",
       "167    12.82        3.37  2.30               19.5       88.0           1.48   \n",
       "168    13.58        2.58  2.69               24.5      105.0           1.55   \n",
       "169    13.40        4.60  2.86               25.0      112.0           1.98   \n",
       "170    12.20        3.03  2.32               19.0       96.0           1.25   \n",
       "171    12.77        2.39  2.28               19.5       86.0           1.39   \n",
       "172    14.16        2.51  2.48               20.0       91.0           1.68   \n",
       "173    13.71        5.65  2.45               20.5       95.0           1.68   \n",
       "174    13.40        3.91  2.48               23.0      102.0           1.80   \n",
       "175    13.27        4.28  2.26               20.0      120.0           1.59   \n",
       "176    13.17        2.59  2.37               20.0      120.0           1.65   \n",
       "177    14.13        4.10  2.74               24.5       96.0           2.05   \n",
       "\n",
       "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0          3.06                  0.28             2.29         5.640000  1.04   \n",
       "1          2.76                  0.26             1.28         4.380000  1.05   \n",
       "2          3.24                  0.30             2.81         5.680000  1.03   \n",
       "3          3.49                  0.24             2.18         7.800000  0.86   \n",
       "4          2.69                  0.39             1.82         4.320000  1.04   \n",
       "5          3.39                  0.34             1.97         6.750000  1.05   \n",
       "6          2.52                  0.30             1.98         5.250000  1.02   \n",
       "7          2.51                  0.31             1.25         5.050000  1.06   \n",
       "8          2.98                  0.29             1.98         5.200000  1.08   \n",
       "9          3.15                  0.22             1.85         7.220000  1.01   \n",
       "10         3.32                  0.22             2.38         5.750000  1.25   \n",
       "11         2.43                  0.26             1.57         5.000000  1.17   \n",
       "12         2.76                  0.29             1.81         5.600000  1.15   \n",
       "13         3.69                  0.43             2.81         5.400000  1.25   \n",
       "14         3.64                  0.29             2.96         7.500000  1.20   \n",
       "15         2.91                  0.30             1.46         7.300000  1.28   \n",
       "16         3.14                  0.33             1.97         6.200000  1.07   \n",
       "17         3.40                  0.40             1.72         6.600000  1.13   \n",
       "18         3.93                  0.32             1.86         8.700000  1.23   \n",
       "19         3.03                  0.17             1.66         5.100000  0.96   \n",
       "20         3.17                  0.24             2.10         5.650000  1.09   \n",
       "21         2.41                  0.25             1.98         4.500000  1.03   \n",
       "22         2.88                  0.27             1.69         3.800000  1.11   \n",
       "23         2.37                  0.26             1.46         3.930000  1.09   \n",
       "24         2.61                  0.28             1.66         3.520000  1.12   \n",
       "25         2.68                  0.47             1.92         3.580000  1.13   \n",
       "26         2.94                  0.34             1.45         4.800000  0.92   \n",
       "27         2.19                  0.27             1.35         3.950000  1.02   \n",
       "28         2.97                  0.37             1.76         4.500000  1.25   \n",
       "29         2.33                  0.26             1.98         4.700000  1.04   \n",
       "..          ...                   ...              ...              ...   ...   \n",
       "148        0.76                  0.45             1.25         8.420000  0.55   \n",
       "149        1.39                  0.34             1.14         9.400000  0.57   \n",
       "150        1.57                  0.22             1.25         8.600000  0.59   \n",
       "151        1.36                  0.24             1.26        10.800000  0.48   \n",
       "152        1.28                  0.26             1.56         7.100000  0.61   \n",
       "153        0.83                  0.61             1.87        10.520000  0.56   \n",
       "154        0.58                  0.53             1.40         7.600000  0.58   \n",
       "155        0.63                  0.61             1.55         7.900000  0.60   \n",
       "156        0.83                  0.48             1.56         9.010000  0.57   \n",
       "157        0.58                  0.63             1.14         7.500000  0.67   \n",
       "158        1.31                  0.53             2.70        13.000000  0.57   \n",
       "159        1.10                  0.52             2.29        11.750000  0.57   \n",
       "160        0.92                  0.50             1.04         7.650000  0.56   \n",
       "161        0.56                  0.50             0.80         5.880000  0.96   \n",
       "162        0.60                  0.60             0.96         5.580000  0.87   \n",
       "163        0.70                  0.40             0.94         5.280000  0.68   \n",
       "164        0.68                  0.41             1.03         9.580000  0.70   \n",
       "165        0.47                  0.52             1.15         6.620000  0.78   \n",
       "166        0.92                  0.43             1.46        10.680000  0.85   \n",
       "167        0.66                  0.40             0.97        10.260000  0.72   \n",
       "168        0.84                  0.39             1.54         8.660000  0.74   \n",
       "169        0.96                  0.27             1.11         8.500000  0.67   \n",
       "170        0.49                  0.40             0.73         5.500000  0.66   \n",
       "171        0.51                  0.48             0.64         9.899999  0.57   \n",
       "172        0.70                  0.44             1.24         9.700000  0.62   \n",
       "173        0.61                  0.52             1.06         7.700000  0.64   \n",
       "174        0.75                  0.43             1.41         7.300000  0.70   \n",
       "175        0.69                  0.43             1.35        10.200000  0.59   \n",
       "176        0.68                  0.53             1.46         9.300000  0.60   \n",
       "177        0.76                  0.56             1.35         9.200000  0.61   \n",
       "\n",
       "     od280/od315_of_diluted_wines  proline  wine_class  \n",
       "0                            3.92   1065.0           0  \n",
       "1                            3.40   1050.0           0  \n",
       "2                            3.17   1185.0           0  \n",
       "3                            3.45   1480.0           0  \n",
       "4                            2.93    735.0           0  \n",
       "5                            2.85   1450.0           0  \n",
       "6                            3.58   1290.0           0  \n",
       "7                            3.58   1295.0           0  \n",
       "8                            2.85   1045.0           0  \n",
       "9                            3.55   1045.0           0  \n",
       "10                           3.17   1510.0           0  \n",
       "11                           2.82   1280.0           0  \n",
       "12                           2.90   1320.0           0  \n",
       "13                           2.73   1150.0           0  \n",
       "14                           3.00   1547.0           0  \n",
       "15                           2.88   1310.0           0  \n",
       "16                           2.65   1280.0           0  \n",
       "17                           2.57   1130.0           0  \n",
       "18                           2.82   1680.0           0  \n",
       "19                           3.36    845.0           0  \n",
       "20                           3.71    780.0           0  \n",
       "21                           3.52    770.0           0  \n",
       "22                           4.00   1035.0           0  \n",
       "23                           3.63   1015.0           0  \n",
       "24                           3.82    845.0           0  \n",
       "25                           3.20    830.0           0  \n",
       "26                           3.22   1195.0           0  \n",
       "27                           2.77   1285.0           0  \n",
       "28                           3.40    915.0           0  \n",
       "29                           3.59   1035.0           0  \n",
       "..                            ...      ...         ...  \n",
       "148                          1.62    650.0           2  \n",
       "149                          1.33    550.0           2  \n",
       "150                          1.30    500.0           2  \n",
       "151                          1.47    480.0           2  \n",
       "152                          1.33    425.0           2  \n",
       "153                          1.51    675.0           2  \n",
       "154                          1.55    640.0           2  \n",
       "155                          1.48    725.0           2  \n",
       "156                          1.64    480.0           2  \n",
       "157                          1.73    880.0           2  \n",
       "158                          1.96    660.0           2  \n",
       "159                          1.78    620.0           2  \n",
       "160                          1.58    520.0           2  \n",
       "161                          1.82    680.0           2  \n",
       "162                          2.11    570.0           2  \n",
       "163                          1.75    675.0           2  \n",
       "164                          1.68    615.0           2  \n",
       "165                          1.75    520.0           2  \n",
       "166                          1.56    695.0           2  \n",
       "167                          1.75    685.0           2  \n",
       "168                          1.80    750.0           2  \n",
       "169                          1.92    630.0           2  \n",
       "170                          1.83    510.0           2  \n",
       "171                          1.63    470.0           2  \n",
       "172                          1.71    660.0           2  \n",
       "173                          1.74    740.0           2  \n",
       "174                          1.56    750.0           2  \n",
       "175                          1.56    835.0           2  \n",
       "176                          1.62    840.0           2  \n",
       "177                          1.60    560.0           2  \n",
       "\n",
       "[178 rows x 14 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exploring the dataset\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 178 entries, 0 to 177\n",
      "Data columns (total 14 columns):\n",
      "alcohol                         178 non-null float64\n",
      "malic_acid                      178 non-null float64\n",
      "ash                             178 non-null float64\n",
      "alcalinity_of_ash               178 non-null float64\n",
      "magnesium                       178 non-null float64\n",
      "total_phenols                   178 non-null float64\n",
      "flavanoids                      178 non-null float64\n",
      "nonflavanoid_phenols            178 non-null float64\n",
      "proanthocyanins                 178 non-null float64\n",
      "color_intensity                 178 non-null float64\n",
      "hue                             178 non-null float64\n",
      "od280/od315_of_diluted_wines    178 non-null float64\n",
      "proline                         178 non-null float64\n",
      "wine_class                      178 non-null int32\n",
      "dtypes: float64(13), int32(1)\n",
      "memory usage: 18.9 KB\n"
     ]
    }
   ],
   "source": [
    "# Verifying if there are any missing values\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "      <th>wine_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alcohol</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.094397</td>\n",
       "      <td>0.211545</td>\n",
       "      <td>-0.310235</td>\n",
       "      <td>0.270798</td>\n",
       "      <td>0.289101</td>\n",
       "      <td>0.236815</td>\n",
       "      <td>-0.155929</td>\n",
       "      <td>0.136698</td>\n",
       "      <td>0.546364</td>\n",
       "      <td>-0.071747</td>\n",
       "      <td>0.072343</td>\n",
       "      <td>0.643720</td>\n",
       "      <td>-0.328222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>malic_acid</th>\n",
       "      <td>0.094397</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.164045</td>\n",
       "      <td>0.288500</td>\n",
       "      <td>-0.054575</td>\n",
       "      <td>-0.335167</td>\n",
       "      <td>-0.411007</td>\n",
       "      <td>0.292977</td>\n",
       "      <td>-0.220746</td>\n",
       "      <td>0.248985</td>\n",
       "      <td>-0.561296</td>\n",
       "      <td>-0.368710</td>\n",
       "      <td>-0.192011</td>\n",
       "      <td>0.437776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ash</th>\n",
       "      <td>0.211545</td>\n",
       "      <td>0.164045</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.443367</td>\n",
       "      <td>0.286587</td>\n",
       "      <td>0.128980</td>\n",
       "      <td>0.115077</td>\n",
       "      <td>0.186230</td>\n",
       "      <td>0.009652</td>\n",
       "      <td>0.258887</td>\n",
       "      <td>-0.074667</td>\n",
       "      <td>0.003911</td>\n",
       "      <td>0.223626</td>\n",
       "      <td>-0.049643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <td>-0.310235</td>\n",
       "      <td>0.288500</td>\n",
       "      <td>0.443367</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>-0.321113</td>\n",
       "      <td>-0.351370</td>\n",
       "      <td>0.361922</td>\n",
       "      <td>-0.197327</td>\n",
       "      <td>0.018732</td>\n",
       "      <td>-0.273955</td>\n",
       "      <td>-0.276769</td>\n",
       "      <td>-0.440597</td>\n",
       "      <td>0.517859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>magnesium</th>\n",
       "      <td>0.270798</td>\n",
       "      <td>-0.054575</td>\n",
       "      <td>0.286587</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.214401</td>\n",
       "      <td>0.195784</td>\n",
       "      <td>-0.256294</td>\n",
       "      <td>0.236441</td>\n",
       "      <td>0.199950</td>\n",
       "      <td>0.055398</td>\n",
       "      <td>0.066004</td>\n",
       "      <td>0.393351</td>\n",
       "      <td>-0.209179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_phenols</th>\n",
       "      <td>0.289101</td>\n",
       "      <td>-0.335167</td>\n",
       "      <td>0.128980</td>\n",
       "      <td>-0.321113</td>\n",
       "      <td>0.214401</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.864564</td>\n",
       "      <td>-0.449935</td>\n",
       "      <td>0.612413</td>\n",
       "      <td>-0.055136</td>\n",
       "      <td>0.433681</td>\n",
       "      <td>0.699949</td>\n",
       "      <td>0.498115</td>\n",
       "      <td>-0.719163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flavanoids</th>\n",
       "      <td>0.236815</td>\n",
       "      <td>-0.411007</td>\n",
       "      <td>0.115077</td>\n",
       "      <td>-0.351370</td>\n",
       "      <td>0.195784</td>\n",
       "      <td>0.864564</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.537900</td>\n",
       "      <td>0.652692</td>\n",
       "      <td>-0.172379</td>\n",
       "      <td>0.543479</td>\n",
       "      <td>0.787194</td>\n",
       "      <td>0.494193</td>\n",
       "      <td>-0.847498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <td>-0.155929</td>\n",
       "      <td>0.292977</td>\n",
       "      <td>0.186230</td>\n",
       "      <td>0.361922</td>\n",
       "      <td>-0.256294</td>\n",
       "      <td>-0.449935</td>\n",
       "      <td>-0.537900</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.365845</td>\n",
       "      <td>0.139057</td>\n",
       "      <td>-0.262640</td>\n",
       "      <td>-0.503270</td>\n",
       "      <td>-0.311385</td>\n",
       "      <td>0.489109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>proanthocyanins</th>\n",
       "      <td>0.136698</td>\n",
       "      <td>-0.220746</td>\n",
       "      <td>0.009652</td>\n",
       "      <td>-0.197327</td>\n",
       "      <td>0.236441</td>\n",
       "      <td>0.612413</td>\n",
       "      <td>0.652692</td>\n",
       "      <td>-0.365845</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.025250</td>\n",
       "      <td>0.295544</td>\n",
       "      <td>0.519067</td>\n",
       "      <td>0.330417</td>\n",
       "      <td>-0.499130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>color_intensity</th>\n",
       "      <td>0.546364</td>\n",
       "      <td>0.248985</td>\n",
       "      <td>0.258887</td>\n",
       "      <td>0.018732</td>\n",
       "      <td>0.199950</td>\n",
       "      <td>-0.055136</td>\n",
       "      <td>-0.172379</td>\n",
       "      <td>0.139057</td>\n",
       "      <td>-0.025250</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.521813</td>\n",
       "      <td>-0.428815</td>\n",
       "      <td>0.316100</td>\n",
       "      <td>0.265668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hue</th>\n",
       "      <td>-0.071747</td>\n",
       "      <td>-0.561296</td>\n",
       "      <td>-0.074667</td>\n",
       "      <td>-0.273955</td>\n",
       "      <td>0.055398</td>\n",
       "      <td>0.433681</td>\n",
       "      <td>0.543479</td>\n",
       "      <td>-0.262640</td>\n",
       "      <td>0.295544</td>\n",
       "      <td>-0.521813</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.565468</td>\n",
       "      <td>0.236183</td>\n",
       "      <td>-0.617369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <td>0.072343</td>\n",
       "      <td>-0.368710</td>\n",
       "      <td>0.003911</td>\n",
       "      <td>-0.276769</td>\n",
       "      <td>0.066004</td>\n",
       "      <td>0.699949</td>\n",
       "      <td>0.787194</td>\n",
       "      <td>-0.503270</td>\n",
       "      <td>0.519067</td>\n",
       "      <td>-0.428815</td>\n",
       "      <td>0.565468</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.312761</td>\n",
       "      <td>-0.788230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>proline</th>\n",
       "      <td>0.643720</td>\n",
       "      <td>-0.192011</td>\n",
       "      <td>0.223626</td>\n",
       "      <td>-0.440597</td>\n",
       "      <td>0.393351</td>\n",
       "      <td>0.498115</td>\n",
       "      <td>0.494193</td>\n",
       "      <td>-0.311385</td>\n",
       "      <td>0.330417</td>\n",
       "      <td>0.316100</td>\n",
       "      <td>0.236183</td>\n",
       "      <td>0.312761</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.633717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wine_class</th>\n",
       "      <td>-0.328222</td>\n",
       "      <td>0.437776</td>\n",
       "      <td>-0.049643</td>\n",
       "      <td>0.517859</td>\n",
       "      <td>-0.209179</td>\n",
       "      <td>-0.719163</td>\n",
       "      <td>-0.847498</td>\n",
       "      <td>0.489109</td>\n",
       "      <td>-0.499130</td>\n",
       "      <td>0.265668</td>\n",
       "      <td>-0.617369</td>\n",
       "      <td>-0.788230</td>\n",
       "      <td>-0.633717</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               alcohol     ...      wine_class\n",
       "alcohol                       1.000000     ...       -0.328222\n",
       "malic_acid                    0.094397     ...        0.437776\n",
       "ash                           0.211545     ...       -0.049643\n",
       "alcalinity_of_ash            -0.310235     ...        0.517859\n",
       "magnesium                     0.270798     ...       -0.209179\n",
       "total_phenols                 0.289101     ...       -0.719163\n",
       "flavanoids                    0.236815     ...       -0.847498\n",
       "nonflavanoid_phenols         -0.155929     ...        0.489109\n",
       "proanthocyanins               0.136698     ...       -0.499130\n",
       "color_intensity               0.546364     ...        0.265668\n",
       "hue                          -0.071747     ...       -0.617369\n",
       "od280/od315_of_diluted_wines  0.072343     ...       -0.788230\n",
       "proline                       0.643720     ...       -0.633717\n",
       "wine_class                   -0.328222     ...        1.000000\n",
       "\n",
       "[14 rows x 14 columns]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Table of correlation among features and Target Variable\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x24c8897e0f0>"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(data=df.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the dataset into independent, X, and dependent, y, variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('wine_class',axis=1)\n",
    "y = df.wine_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = StandardScaler()\n",
    "X = scale.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(data=X, columns=df.columns[:-1], )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the dataset into training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=101)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BUILDING THE ANN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_out_nodes = int(len(X_train.columns) / 2)\n",
    "input_shp = (len(X_train.columns),)\n",
    "\n",
    "# Initializing the ANN\n",
    "ann = Sequential()\n",
    "\n",
    "# First Hidden Layer with Input Layer\n",
    "ann.add(Dense(units=n_out_nodes, activation='relu', \n",
    "              kernel_initializer='uniform',input_shape=input_shp)\n",
    "       )\n",
    "\n",
    "# Second Hidden Layer\n",
    "ann.add(Dense(units=n_out_nodes, activation='relu', kernel_initializer='uniform'))\n",
    "\n",
    "# Output Layer\n",
    "ann.add(Dense(units=3, activation='softmax', kernel_initializer='uniform'))\n",
    "\n",
    "# Compiling the ANN model\n",
    "ann.compile(optimizer=keras.optimizers.Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initializing KNN, Decision Tree and Random Forest Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_param = {'n_neighbors':list(range(1,51))}\n",
    "knn_grid = GridSearchCV(estimator=KNeighborsClassifier(), param_grid=knn_param, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_param = {'criterion':['gini','entropy']}\n",
    "dt_grid = GridSearchCV(estimator=DecisionTreeClassifier(), param_grid=dt_param, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_param = {'n_estimators': list(range(5,51)), 'criterion':['gini','entropy']}\n",
    "rf_grid = GridSearchCV(estimator=RandomForestClassifier(), param_grid=rf_param, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 1.0985 - acc: 0.3459\n",
      "Epoch 2/250\n",
      "133/133 [==============================] - 0s 158us/step - loss: 1.0973 - acc: 0.4060\n",
      "Epoch 3/250\n",
      "133/133 [==============================] - 0s 196us/step - loss: 1.0957 - acc: 0.4060\n",
      "Epoch 4/250\n",
      "133/133 [==============================] - 0s 245us/step - loss: 1.0922 - acc: 0.4060\n",
      "Epoch 5/250\n",
      "133/133 [==============================] - 0s 245us/step - loss: 1.0844 - acc: 0.4060\n",
      "Epoch 6/250\n",
      "133/133 [==============================] - 0s 233us/step - loss: 1.0704 - acc: 0.4060\n",
      "Epoch 7/250\n",
      "133/133 [==============================] - 0s 245us/step - loss: 1.0484 - acc: 0.4211\n",
      "Epoch 8/250\n",
      "133/133 [==============================] - 0s 218us/step - loss: 1.0150 - acc: 0.5940\n",
      "Epoch 9/250\n",
      "133/133 [==============================] - 0s 256us/step - loss: 0.9694 - acc: 0.6692\n",
      "Epoch 10/250\n",
      "133/133 [==============================] - 0s 271us/step - loss: 0.9132 - acc: 0.6767\n",
      "Epoch 11/250\n",
      "133/133 [==============================] - 0s 233us/step - loss: 0.8486 - acc: 0.6692\n",
      "Epoch 12/250\n",
      "133/133 [==============================] - 0s 241us/step - loss: 0.7781 - acc: 0.6767\n",
      "Epoch 13/250\n",
      "133/133 [==============================] - 0s 260us/step - loss: 0.7058 - acc: 0.6842\n",
      "Epoch 14/250\n",
      "133/133 [==============================] - 0s 233us/step - loss: 0.6323 - acc: 0.9248\n",
      "Epoch 15/250\n",
      "133/133 [==============================] - 0s 226us/step - loss: 0.5583 - acc: 0.9474\n",
      "Epoch 16/250\n",
      "133/133 [==============================] - 0s 203us/step - loss: 0.4867 - acc: 0.9474\n",
      "Epoch 17/250\n",
      "133/133 [==============================] - 0s 263us/step - loss: 0.4191 - acc: 0.9699\n",
      "Epoch 18/250\n",
      "133/133 [==============================] - 0s 222us/step - loss: 0.3600 - acc: 0.9624\n",
      "Epoch 19/250\n",
      "133/133 [==============================] - 0s 256us/step - loss: 0.3059 - acc: 0.9699\n",
      "Epoch 20/250\n",
      "133/133 [==============================] - 0s 222us/step - loss: 0.2613 - acc: 0.9699\n",
      "Epoch 21/250\n",
      "133/133 [==============================] - 0s 286us/step - loss: 0.2257 - acc: 0.9699\n",
      "Epoch 22/250\n",
      "133/133 [==============================] - 0s 226us/step - loss: 0.1959 - acc: 0.9774\n",
      "Epoch 23/250\n",
      "133/133 [==============================] - 0s 192us/step - loss: 0.1717 - acc: 0.9774\n",
      "Epoch 24/250\n",
      "133/133 [==============================] - 0s 218us/step - loss: 0.1515 - acc: 0.9774\n",
      "Epoch 25/250\n",
      "133/133 [==============================] - 0s 226us/step - loss: 0.1352 - acc: 0.9850\n",
      "Epoch 26/250\n",
      "133/133 [==============================] - 0s 188us/step - loss: 0.1234 - acc: 0.9850\n",
      "Epoch 27/250\n",
      "133/133 [==============================] - 0s 173us/step - loss: 0.1098 - acc: 0.9850\n",
      "Epoch 28/250\n",
      "133/133 [==============================] - 0s 226us/step - loss: 0.1004 - acc: 0.9850\n",
      "Epoch 29/250\n",
      "133/133 [==============================] - 0s 211us/step - loss: 0.0922 - acc: 0.9850\n",
      "Epoch 30/250\n",
      "133/133 [==============================] - 0s 150us/step - loss: 0.0837 - acc: 0.9850\n",
      "Epoch 31/250\n",
      "133/133 [==============================] - 0s 233us/step - loss: 0.0790 - acc: 0.9925\n",
      "Epoch 32/250\n",
      "133/133 [==============================] - 0s 199us/step - loss: 0.0726 - acc: 1.0000\n",
      "Epoch 33/250\n",
      "133/133 [==============================] - 0s 166us/step - loss: 0.0675 - acc: 0.9925\n",
      "Epoch 34/250\n",
      "133/133 [==============================] - 0s 203us/step - loss: 0.0627 - acc: 0.9925\n",
      "Epoch 35/250\n",
      "133/133 [==============================] - 0s 222us/step - loss: 0.0589 - acc: 1.0000\n",
      "Epoch 36/250\n",
      "133/133 [==============================] - 0s 207us/step - loss: 0.0551 - acc: 1.0000\n",
      "Epoch 37/250\n",
      "133/133 [==============================] - 0s 166us/step - loss: 0.0520 - acc: 1.0000\n",
      "Epoch 38/250\n",
      "133/133 [==============================] - 0s 181us/step - loss: 0.0493 - acc: 1.0000\n",
      "Epoch 39/250\n",
      "133/133 [==============================] - 0s 199us/step - loss: 0.0465 - acc: 1.0000\n",
      "Epoch 40/250\n",
      "133/133 [==============================] - 0s 166us/step - loss: 0.0442 - acc: 1.0000\n",
      "Epoch 41/250\n",
      "133/133 [==============================] - 0s 188us/step - loss: 0.0418 - acc: 1.0000\n",
      "Epoch 42/250\n",
      "133/133 [==============================] - 0s 218us/step - loss: 0.0395 - acc: 1.0000\n",
      "Epoch 43/250\n",
      "133/133 [==============================] - 0s 192us/step - loss: 0.0378 - acc: 1.0000\n",
      "Epoch 44/250\n",
      "133/133 [==============================] - 0s 211us/step - loss: 0.0361 - acc: 1.0000\n",
      "Epoch 45/250\n",
      "133/133 [==============================] - 0s 150us/step - loss: 0.0344 - acc: 1.0000\n",
      "Epoch 46/250\n",
      "133/133 [==============================] - 0s 196us/step - loss: 0.0326 - acc: 1.0000\n",
      "Epoch 47/250\n",
      "133/133 [==============================] - 0s 188us/step - loss: 0.0311 - acc: 1.0000\n",
      "Epoch 48/250\n",
      "133/133 [==============================] - 0s 181us/step - loss: 0.0298 - acc: 1.0000\n",
      "Epoch 49/250\n",
      "133/133 [==============================] - 0s 188us/step - loss: 0.0288 - acc: 1.0000\n",
      "Epoch 50/250\n",
      "133/133 [==============================] - 0s 158us/step - loss: 0.0274 - acc: 1.0000\n",
      "Epoch 51/250\n",
      "133/133 [==============================] - 0s 196us/step - loss: 0.0263 - acc: 1.0000\n",
      "Epoch 52/250\n",
      "133/133 [==============================] - 0s 173us/step - loss: 0.0252 - acc: 1.0000\n",
      "Epoch 53/250\n",
      "133/133 [==============================] - 0s 192us/step - loss: 0.0243 - acc: 1.0000\n",
      "Epoch 54/250\n",
      "133/133 [==============================] - 0s 241us/step - loss: 0.0232 - acc: 1.0000\n",
      "Epoch 55/250\n",
      "133/133 [==============================] - 0s 226us/step - loss: 0.0223 - acc: 1.0000\n",
      "Epoch 56/250\n",
      "133/133 [==============================] - 0s 203us/step - loss: 0.0217 - acc: 1.0000\n",
      "Epoch 57/250\n",
      "133/133 [==============================] - 0s 196us/step - loss: 0.0208 - acc: 1.0000\n",
      "Epoch 58/250\n",
      "133/133 [==============================] - 0s 181us/step - loss: 0.0200 - acc: 1.0000\n",
      "Epoch 59/250\n",
      "133/133 [==============================] - 0s 158us/step - loss: 0.0193 - acc: 1.0000\n",
      "Epoch 60/250\n",
      "133/133 [==============================] - 0s 172us/step - loss: 0.0187 - acc: 1.0000\n",
      "Epoch 61/250\n",
      "133/133 [==============================] - 0s 150us/step - loss: 0.0181 - acc: 1.0000\n",
      "Epoch 62/250\n",
      "133/133 [==============================] - 0s 166us/step - loss: 0.0175 - acc: 1.0000\n",
      "Epoch 63/250\n",
      "133/133 [==============================] - 0s 181us/step - loss: 0.0170 - acc: 1.0000\n",
      "Epoch 64/250\n",
      "133/133 [==============================] - 0s 169us/step - loss: 0.0164 - acc: 1.0000\n",
      "Epoch 65/250\n",
      "133/133 [==============================] - 0s 188us/step - loss: 0.0158 - acc: 1.0000\n",
      "Epoch 66/250\n",
      "133/133 [==============================] - 0s 241us/step - loss: 0.0153 - acc: 1.0000\n",
      "Epoch 67/250\n",
      "133/133 [==============================] - 0s 233us/step - loss: 0.0148 - acc: 1.0000\n",
      "Epoch 68/250\n",
      "133/133 [==============================] - 0s 173us/step - loss: 0.0143 - acc: 1.0000\n",
      "Epoch 69/250\n",
      "133/133 [==============================] - 0s 188us/step - loss: 0.0139 - acc: 1.0000\n",
      "Epoch 70/250\n",
      "133/133 [==============================] - 0s 150us/step - loss: 0.0136 - acc: 1.0000\n",
      "Epoch 71/250\n",
      "133/133 [==============================] - 0s 188us/step - loss: 0.0131 - acc: 1.0000\n",
      "Epoch 72/250\n",
      "133/133 [==============================] - 0s 158us/step - loss: 0.0128 - acc: 1.0000\n",
      "Epoch 73/250\n",
      "133/133 [==============================] - 0s 188us/step - loss: 0.0124 - acc: 1.0000\n",
      "Epoch 74/250\n",
      "133/133 [==============================] - 0s 166us/step - loss: 0.0120 - acc: 1.0000\n",
      "Epoch 75/250\n",
      "133/133 [==============================] - 0s 168us/step - loss: 0.0116 - acc: 1.0000\n",
      "Epoch 76/250\n",
      "133/133 [==============================] - 0s 226us/step - loss: 0.0114 - acc: 1.0000\n",
      "Epoch 77/250\n",
      "133/133 [==============================] - 0s 301us/step - loss: 0.0110 - acc: 1.0000\n",
      "Epoch 78/250\n",
      "133/133 [==============================] - 0s 241us/step - loss: 0.0107 - acc: 1.0000\n",
      "Epoch 79/250\n",
      "133/133 [==============================] - 0s 158us/step - loss: 0.0104 - acc: 1.0000\n",
      "Epoch 80/250\n",
      "133/133 [==============================] - 0s 166us/step - loss: 0.0101 - acc: 1.0000\n",
      "Epoch 81/250\n",
      "133/133 [==============================] - 0s 158us/step - loss: 0.0098 - acc: 1.0000\n",
      "Epoch 82/250\n",
      "133/133 [==============================] - 0s 147us/step - loss: 0.0095 - acc: 1.0000\n",
      "Epoch 83/250\n",
      "133/133 [==============================] - 0s 188us/step - loss: 0.0093 - acc: 1.0000\n",
      "Epoch 84/250\n",
      "133/133 [==============================] - 0s 166us/step - loss: 0.0090 - acc: 1.0000\n",
      "Epoch 85/250\n",
      "133/133 [==============================] - 0s 200us/step - loss: 0.0088 - acc: 1.0000\n",
      "Epoch 86/250\n",
      "133/133 [==============================] - 0s 135us/step - loss: 0.0084 - acc: 1.0000\n",
      "Epoch 87/250\n",
      "133/133 [==============================] - 0s 218us/step - loss: 0.0082 - acc: 1.0000\n",
      "Epoch 88/250\n",
      "133/133 [==============================] - 0s 203us/step - loss: 0.0080 - acc: 1.0000\n",
      "Epoch 89/250\n",
      "133/133 [==============================] - 0s 196us/step - loss: 0.0078 - acc: 1.0000\n",
      "Epoch 90/250\n",
      "133/133 [==============================] - 0s 233us/step - loss: 0.0076 - acc: 1.0000\n",
      "Epoch 91/250\n",
      "133/133 [==============================] - 0s 233us/step - loss: 0.0074 - acc: 1.0000\n",
      "Epoch 92/250\n",
      "133/133 [==============================] - 0s 218us/step - loss: 0.0072 - acc: 1.0000\n",
      "Epoch 93/250\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.0023 - acc: 1.000 - 0s 241us/step - loss: 0.0070 - acc: 1.0000\n",
      "Epoch 94/250\n",
      "133/133 [==============================] - 0s 196us/step - loss: 0.0069 - acc: 1.0000\n",
      "Epoch 95/250\n",
      "133/133 [==============================] - 0s 211us/step - loss: 0.0067 - acc: 1.0000\n",
      "Epoch 96/250\n",
      "133/133 [==============================] - 0s 173us/step - loss: 0.0065 - acc: 1.0000\n",
      "Epoch 97/250\n",
      "133/133 [==============================] - 0s 196us/step - loss: 0.0063 - acc: 1.0000\n",
      "Epoch 98/250\n",
      "133/133 [==============================] - 0s 211us/step - loss: 0.0062 - acc: 1.0000\n",
      "Epoch 99/250\n",
      "133/133 [==============================] - 0s 181us/step - loss: 0.0060 - acc: 1.0000\n",
      "Epoch 100/250\n",
      "133/133 [==============================] - 0s 218us/step - loss: 0.0059 - acc: 1.0000\n",
      "Epoch 101/250\n",
      "133/133 [==============================] - 0s 184us/step - loss: 0.0057 - acc: 1.0000\n",
      "Epoch 102/250\n",
      "133/133 [==============================] - 0s 203us/step - loss: 0.0056 - acc: 1.0000\n",
      "Epoch 103/250\n",
      "133/133 [==============================] - 0s 211us/step - loss: 0.0055 - acc: 1.0000\n",
      "Epoch 104/250\n",
      "133/133 [==============================] - 0s 196us/step - loss: 0.0054 - acc: 1.0000\n",
      "Epoch 105/250\n",
      "133/133 [==============================] - 0s 203us/step - loss: 0.0052 - acc: 1.0000\n",
      "Epoch 106/250\n",
      "133/133 [==============================] - 0s 173us/step - loss: 0.0051 - acc: 1.0000\n",
      "Epoch 107/250\n",
      "133/133 [==============================] - 0s 211us/step - loss: 0.0050 - acc: 1.0000\n",
      "Epoch 108/250\n",
      "133/133 [==============================] - 0s 263us/step - loss: 0.0049 - acc: 1.0000\n",
      "Epoch 109/250\n",
      "133/133 [==============================] - 0s 278us/step - loss: 0.0048 - acc: 1.0000\n",
      "Epoch 110/250\n",
      "133/133 [==============================] - 0s 459us/step - loss: 0.0047 - acc: 1.0000\n",
      "Epoch 111/250\n",
      "133/133 [==============================] - 0s 256us/step - loss: 0.0046 - acc: 1.0000\n",
      "Epoch 112/250\n",
      "133/133 [==============================] - 0s 207us/step - loss: 0.0045 - acc: 1.0000\n",
      "Epoch 113/250\n",
      "133/133 [==============================] - 0s 203us/step - loss: 0.0044 - acc: 1.0000\n",
      "Epoch 114/250\n",
      "133/133 [==============================] - 0s 188us/step - loss: 0.0043 - acc: 1.0000\n",
      "Epoch 115/250\n",
      "133/133 [==============================] - 0s 271us/step - loss: 0.0043 - acc: 1.0000\n",
      "Epoch 116/250\n",
      "133/133 [==============================] - 0s 256us/step - loss: 0.0042 - acc: 1.0000\n",
      "Epoch 117/250\n",
      "133/133 [==============================] - 0s 293us/step - loss: 0.0041 - acc: 1.0000\n",
      "Epoch 118/250\n",
      "133/133 [==============================] - 0s 218us/step - loss: 0.0040 - acc: 1.0000\n",
      "Epoch 119/250\n",
      "133/133 [==============================] - 0s 229us/step - loss: 0.0039 - acc: 1.0000\n",
      "Epoch 120/250\n",
      "133/133 [==============================] - 0s 207us/step - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 121/250\n",
      "133/133 [==============================] - 0s 218us/step - loss: 0.0037 - acc: 1.0000\n",
      "Epoch 122/250\n",
      "133/133 [==============================] - 0s 184us/step - loss: 0.0037 - acc: 1.0000\n",
      "Epoch 123/250\n",
      "133/133 [==============================] - 0s 241us/step - loss: 0.0036 - acc: 1.0000\n",
      "Epoch 124/250\n",
      "133/133 [==============================] - 0s 211us/step - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 125/250\n",
      "133/133 [==============================] - 0s 226us/step - loss: 0.0034 - acc: 1.0000\n",
      "Epoch 126/250\n",
      "133/133 [==============================] - 0s 196us/step - loss: 0.0034 - acc: 1.0000\n",
      "Epoch 127/250\n",
      "133/133 [==============================] - 0s 211us/step - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 128/250\n",
      "133/133 [==============================] - 0s 188us/step - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 129/250\n",
      "133/133 [==============================] - 0s 188us/step - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 130/250\n",
      "133/133 [==============================] - 0s 188us/step - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 131/250\n",
      "133/133 [==============================] - 0s 196us/step - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 132/250\n",
      "133/133 [==============================] - 0s 173us/step - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 133/250\n",
      "133/133 [==============================] - 0s 188us/step - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 134/250\n",
      "133/133 [==============================] - 0s 196us/step - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 135/250\n",
      "133/133 [==============================] - 0s 177us/step - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 136/250\n",
      "133/133 [==============================] - 0s 162us/step - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 137/250\n",
      "133/133 [==============================] - 0s 196us/step - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 138/250\n",
      "133/133 [==============================] - 0s 166us/step - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 139/250\n",
      "133/133 [==============================] - 0s 203us/step - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 140/250\n",
      "133/133 [==============================] - 0s 188us/step - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 141/250\n",
      "133/133 [==============================] - 0s 181us/step - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 142/250\n",
      "133/133 [==============================] - 0s 188us/step - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 143/250\n",
      "133/133 [==============================] - 0s 163us/step - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 144/250\n",
      "133/133 [==============================] - 0s 211us/step - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 145/250\n",
      "133/133 [==============================] - 0s 211us/step - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 146/250\n",
      "133/133 [==============================] - 0s 158us/step - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 147/250\n",
      "133/133 [==============================] - 0s 177us/step - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 148/250\n",
      "133/133 [==============================] - 0s 211us/step - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 149/250\n",
      "133/133 [==============================] - 0s 196us/step - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 150/250\n",
      "133/133 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 151/250\n",
      "133/133 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 152/250\n",
      "133/133 [==============================] - 0s 203us/step - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 153/250\n",
      "133/133 [==============================] - 0s 188us/step - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 154/250\n",
      "133/133 [==============================] - 0s 155us/step - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 155/250\n",
      "133/133 [==============================] - 0s 188us/step - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 156/250\n",
      "133/133 [==============================] - 0s 203us/step - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 157/250\n",
      "133/133 [==============================] - 0s 162us/step - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 158/250\n",
      "133/133 [==============================] - 0s 195us/step - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 159/250\n",
      "133/133 [==============================] - 0s 166us/step - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 160/250\n",
      "133/133 [==============================] - 0s 181us/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 161/250\n",
      "133/133 [==============================] - 0s 248us/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 162/250\n",
      "133/133 [==============================] - 0s 166us/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 163/250\n",
      "133/133 [==============================] - 0s 218us/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 164/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 169us/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 165/250\n",
      "133/133 [==============================] - 0s 181us/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 166/250\n",
      "133/133 [==============================] - 0s 158us/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 167/250\n",
      "133/133 [==============================] - 0s 271us/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 168/250\n",
      "133/133 [==============================] - 0s 166us/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 169/250\n",
      "133/133 [==============================] - 0s 263us/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 170/250\n",
      "133/133 [==============================] - 0s 282us/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 171/250\n",
      "133/133 [==============================] - 0s 222us/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 172/250\n",
      "133/133 [==============================] - 0s 248us/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 173/250\n",
      "133/133 [==============================] - 0s 233us/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 174/250\n",
      "133/133 [==============================] - 0s 203us/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 175/250\n",
      "133/133 [==============================] - 0s 233us/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 176/250\n",
      "133/133 [==============================] - 0s 222us/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 177/250\n",
      "133/133 [==============================] - 0s 263us/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 178/250\n",
      "133/133 [==============================] - 0s 173us/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 179/250\n",
      "133/133 [==============================] - 0s 196us/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 180/250\n",
      "133/133 [==============================] - 0s 184us/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 181/250\n",
      "133/133 [==============================] - 0s 226us/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 182/250\n",
      "133/133 [==============================] - 0s 211us/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 183/250\n",
      "133/133 [==============================] - 0s 208us/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 184/250\n",
      "133/133 [==============================] - 0s 211us/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 185/250\n",
      "133/133 [==============================] - 0s 241us/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 186/250\n",
      "133/133 [==============================] - 0s 207us/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 187/250\n",
      "133/133 [==============================] - 0s 203us/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 188/250\n",
      "133/133 [==============================] - 0s 166us/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 189/250\n",
      "133/133 [==============================] - 0s 208us/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 190/250\n",
      "133/133 [==============================] - 0s 181us/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 191/250\n",
      "133/133 [==============================] - 0s 226us/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 192/250\n",
      "133/133 [==============================] - 0s 199us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 193/250\n",
      "133/133 [==============================] - 0s 184us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 194/250\n",
      "133/133 [==============================] - 0s 211us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 195/250\n",
      "133/133 [==============================] - 0s 196us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 196/250\n",
      "133/133 [==============================] - 0s 215us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 197/250\n",
      "133/133 [==============================] - 0s 188us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 198/250\n",
      "133/133 [==============================] - 0s 181us/step - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 199/250\n",
      "133/133 [==============================] - 0s 173us/step - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 200/250\n",
      "133/133 [==============================] - 0s 218us/step - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 201/250\n",
      "133/133 [==============================] - 0s 196us/step - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 202/250\n",
      "133/133 [==============================] - 0s 301us/step - loss: 9.9028e-04 - acc: 1.0000\n",
      "Epoch 203/250\n",
      "133/133 [==============================] - 0s 196us/step - loss: 9.7584e-04 - acc: 1.0000\n",
      "Epoch 204/250\n",
      "133/133 [==============================] - 0s 233us/step - loss: 9.6334e-04 - acc: 1.0000\n",
      "Epoch 205/250\n",
      "133/133 [==============================] - 0s 226us/step - loss: 9.4894e-04 - acc: 1.0000\n",
      "Epoch 206/250\n",
      "133/133 [==============================] - 0s 188us/step - loss: 9.3538e-04 - acc: 1.0000\n",
      "Epoch 207/250\n",
      "133/133 [==============================] - 0s 218us/step - loss: 9.2303e-04 - acc: 1.0000\n",
      "Epoch 208/250\n",
      "133/133 [==============================] - 0s 192us/step - loss: 9.0820e-04 - acc: 1.0000\n",
      "Epoch 209/250\n",
      "133/133 [==============================] - 0s 213us/step - loss: 8.9749e-04 - acc: 1.0000\n",
      "Epoch 210/250\n",
      "133/133 [==============================] - 0s 203us/step - loss: 8.8579e-04 - acc: 1.0000\n",
      "Epoch 211/250\n",
      "133/133 [==============================] - 0s 196us/step - loss: 8.7382e-04 - acc: 1.0000\n",
      "Epoch 212/250\n",
      "133/133 [==============================] - 0s 203us/step - loss: 8.6330e-04 - acc: 1.0000\n",
      "Epoch 213/250\n",
      "133/133 [==============================] - 0s 188us/step - loss: 8.5058e-04 - acc: 1.0000\n",
      "Epoch 214/250\n",
      "133/133 [==============================] - 0s 181us/step - loss: 8.4151e-04 - acc: 1.0000\n",
      "Epoch 215/250\n",
      "133/133 [==============================] - 0s 188us/step - loss: 8.2750e-04 - acc: 1.0000\n",
      "Epoch 216/250\n",
      "133/133 [==============================] - 0s 181us/step - loss: 8.2107e-04 - acc: 1.0000\n",
      "Epoch 217/250\n",
      "133/133 [==============================] - 0s 166us/step - loss: 8.1036e-04 - acc: 1.0000\n",
      "Epoch 218/250\n",
      "133/133 [==============================] - 0s 166us/step - loss: 7.9918e-04 - acc: 1.0000\n",
      "Epoch 219/250\n",
      "133/133 [==============================] - 0s 184us/step - loss: 7.8896e-04 - acc: 1.0000\n",
      "Epoch 220/250\n",
      "133/133 [==============================] - 0s 199us/step - loss: 7.7864e-04 - acc: 1.0000\n",
      "Epoch 221/250\n",
      "133/133 [==============================] - 0s 196us/step - loss: 7.7052e-04 - acc: 1.0000\n",
      "Epoch 222/250\n",
      "133/133 [==============================] - 0s 135us/step - loss: 7.6138e-04 - acc: 1.0000\n",
      "Epoch 223/250\n",
      "133/133 [==============================] - 0s 211us/step - loss: 7.5194e-04 - acc: 1.0000\n",
      "Epoch 224/250\n",
      "133/133 [==============================] - 0s 188us/step - loss: 7.4271e-04 - acc: 1.0000\n",
      "Epoch 225/250\n",
      "133/133 [==============================] - 0s 181us/step - loss: 7.3236e-04 - acc: 1.0000\n",
      "Epoch 226/250\n",
      "133/133 [==============================] - 0s 166us/step - loss: 7.2223e-04 - acc: 1.0000\n",
      "Epoch 227/250\n",
      "133/133 [==============================] - 0s 211us/step - loss: 7.1303e-04 - acc: 1.0000\n",
      "Epoch 228/250\n",
      "133/133 [==============================] - 0s 211us/step - loss: 7.0383e-04 - acc: 1.0000\n",
      "Epoch 229/250\n",
      "133/133 [==============================] - 0s 166us/step - loss: 6.9555e-04 - acc: 1.0000\n",
      "Epoch 230/250\n",
      "133/133 [==============================] - 0s 196us/step - loss: 6.8785e-04 - acc: 1.0000\n",
      "Epoch 231/250\n",
      "133/133 [==============================] - 0s 185us/step - loss: 6.7836e-04 - acc: 1.0000\n",
      "Epoch 232/250\n",
      "133/133 [==============================] - 0s 166us/step - loss: 6.7044e-04 - acc: 1.0000\n",
      "Epoch 233/250\n",
      "133/133 [==============================] - 0s 150us/step - loss: 6.6197e-04 - acc: 1.0000\n",
      "Epoch 234/250\n",
      "133/133 [==============================] - 0s 196us/step - loss: 6.5348e-04 - acc: 1.0000\n",
      "Epoch 235/250\n",
      "133/133 [==============================] - 0s 158us/step - loss: 6.4768e-04 - acc: 1.0000\n",
      "Epoch 236/250\n",
      "133/133 [==============================] - 0s 196us/step - loss: 6.3846e-04 - acc: 1.0000\n",
      "Epoch 237/250\n",
      "133/133 [==============================] - 0s 188us/step - loss: 6.2936e-04 - acc: 1.0000\n",
      "Epoch 238/250\n",
      "133/133 [==============================] - 0s 199us/step - loss: 6.2409e-04 - acc: 1.0000\n",
      "Epoch 239/250\n",
      "133/133 [==============================] - 0s 173us/step - loss: 6.1427e-04 - acc: 1.0000\n",
      "Epoch 240/250\n",
      "133/133 [==============================] - 0s 196us/step - loss: 6.1040e-04 - acc: 1.0000\n",
      "Epoch 241/250\n",
      "133/133 [==============================] - 0s 162us/step - loss: 6.0235e-04 - acc: 1.0000\n",
      "Epoch 242/250\n",
      "133/133 [==============================] - 0s 169us/step - loss: 5.9293e-04 - acc: 1.0000\n",
      "Epoch 243/250\n",
      "133/133 [==============================] - 0s 181us/step - loss: 5.8705e-04 - acc: 1.0000\n",
      "Epoch 244/250\n",
      "133/133 [==============================] - 0s 173us/step - loss: 5.8027e-04 - acc: 1.0000\n",
      "Epoch 245/250\n",
      "133/133 [==============================] - 0s 166us/step - loss: 5.7419e-04 - acc: 1.0000\n",
      "Epoch 246/250\n",
      "133/133 [==============================] - 0s 149us/step - loss: 5.6446e-04 - acc: 1.0000\n",
      "Epoch 247/250\n",
      "133/133 [==============================] - 0s 211us/step - loss: 5.5891e-04 - acc: 1.0000\n",
      "Epoch 248/250\n",
      "133/133 [==============================] - 0s 286us/step - loss: 5.5162e-04 - acc: 1.0000\n",
      "Epoch 249/250\n",
      "133/133 [==============================] - 0s 177us/step - loss: 5.4609e-04 - acc: 1.0000\n",
      "Epoch 250/250\n",
      "133/133 [==============================] - 0s 181us/step - loss: 5.3949e-04 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24cf50f4e80>"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ANN\n",
    "from pandas import get_dummies\n",
    "\n",
    "y_ann = get_dummies(y_train)\n",
    "ann.fit(X_train,y_ann,batch_size=10,epochs=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Params: {'n_neighbors': 1}\n",
      "DTree Params: {'criterion': 'gini'}\n",
      "Random For. Params: {'criterion': 'gini', 'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "knn_grid.fit(X_train,y_train)\n",
    "dt_grid.fit(X_train,y_train)\n",
    "rf_grid.fit(X_train,y_train)\n",
    "\n",
    "print('KNN Params:', knn_grid.best_params_)\n",
    "print('DTree Params:', dt_grid.best_params_)\n",
    "print('Random For. Params:', rf_grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_pred = ann.predict_classes(X_test)\n",
    "knn_pred = knn_grid.predict(X_test)\n",
    "dt_pred = dt_grid.predict(X_test)\n",
    "rf_pred = rf_grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(data=list(zip(y_test,knn_pred,dt_pred,rf_pred,ann_pred)), index=y_test.index,\n",
    "                       columns=['True Value','KNN Pred.', 'DTree Pred.', 'Random For. Pred.','ANN Pred.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>True Value</th>\n",
       "      <th>KNN Pred.</th>\n",
       "      <th>DTree Pred.</th>\n",
       "      <th>Random For. Pred.</th>\n",
       "      <th>ANN Pred.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     True Value  KNN Pred.  DTree Pred.  Random For. Pred.  ANN Pred.\n",
       "37            0          0            0                  0          0\n",
       "32            0          0            0                  0          0\n",
       "148           2          2            2                  2          2\n",
       "42            0          0            0                  0          0\n",
       "153           2          2            2                  2          2"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Models</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RndFor</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ANN</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN</td>\n",
       "      <td>95.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DTree</td>\n",
       "      <td>91.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Models  Accuracy\n",
       "2  RndFor     100.0\n",
       "3     ANN     100.0\n",
       "0     KNN      95.6\n",
       "1   DTree      91.1"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_acc = round(accuracy_score(y_test, knn_pred) * 100, 1)\n",
    "dt_acc = round(accuracy_score(y_test, dt_pred) * 100, 1)\n",
    "rf_acc = round(accuracy_score(y_test, rf_pred) * 100, 1)\n",
    "ann_acc = round(accuracy_score(y_test, ann_pred) * 100, 1)\n",
    "\n",
    "names = ['KNN','DTree','RndFor','ANN']\n",
    "values = [knn_acc, dt_acc, rf_acc, ann_acc]\n",
    "\n",
    "accuracy_table = pd.DataFrame(data=list(zip(names,values)), columns=['Models','Accuracy'])\n",
    "accuracy_table.sort_values(by='Accuracy',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x24cff6f2f98>"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(x='Models',y='Accuracy',data=accuracy_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
